{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6d8c8c-a9d7-4a88-b63e-4231e05bf4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout\n",
    "import time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c36c02d-e040-4467-b582-eedd948798cb",
   "metadata": {},
   "source": [
    "We want to scape data from every season from 2012 to 2022. We need to be thorough in order to give as much data to our machine as possible, \n",
    "giving it the best chance possible to be correct when we test it out over the current 2023 season.\n",
    "\n",
    "Below I want to write out the different tables of data that I believe necessary, and plan out where everything will go so the data cleaning phase \n",
    "is less complex. \n",
    "\n",
    "\n",
    "\n",
    "For each season, we want each team's regular season stats. The season stats are composed of 4 tables: \n",
    "\n",
    "    - teams_standard_batting (Team Batting)\n",
    "    - teams_standard_pitching (Team Pitching)\n",
    "    - team_output (Wins Above Avg By Position)\n",
    "    - teams_standard_fielding (Team Fielding)\n",
    "\n",
    "    *All of these tables can be acquired through \"Share & Export\" as csv or excel files and should be utilized to reduce scrapping workload.\n",
    "\n",
    "    There are 30 teams with data for each season. \n",
    "\n",
    "\n",
    "\n",
    "In addition to each team's stats per season, we need to grab the results of each game played during the \n",
    "regular season of each season from 2012 to 2022. \n",
    "    \n",
    "    This means the data we need to grab is from the schedule & results of each team in each year. \n",
    "\n",
    "    For each team in a season, there are 2 tables to grab:\n",
    "\n",
    "        - results (Season summary table)\n",
    "        - team_schedule (Team Game-By-Game Schedule (exportable))\n",
    "\n",
    "\n",
    "\n",
    "And with all these tables I will make one large data set that has each teams relavant metrics that will be trained to decide:\n",
    "\n",
    "    Will team A beat team B. 1 for yes, 0 for no. \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7ec348f-86bd-4521-88c0-c88a4dbe7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to grab seasons 2012 through 2022\n",
    "SEASONS = list(range(2012,2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6577140b-0a97-4b84-bc32-7e4026953367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEASONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39702655-de2c-47f5-aed5-907de1a8e957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d3db03-ed9d-4cfd-a172-cd41aea489b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize where the data tables are going to be stored once they are scrapped.\n",
    "DATA_DIR = \"data\"\n",
    "TEAM_BATTING_DIR = os.path.join(DATA_DIR, \"team_batting\")\n",
    "TEAM_FIELDING_DIR = os.path.join(DATA_DIR, \"team_fielding\")\n",
    "TEAM_PITCHING_DIR = os.path.join(DATA_DIR, \"team_pitching\")\n",
    "TEAM_SCHEDULE_DIR = os.path.join(DATA_DIR, \"team_schedule\")\n",
    "SEASON_SUMMARY_DIR = os.path.join(DATA_DIR, \"season_summary\")\n",
    "SEASON_STATS_DIR = os.path.join(DATA_DIR, \"season_stats\")\n",
    "GAMES_DIR = os.path.join(DATA_DIR, \"games\")\n",
    "WINS_ABOVE_AVG_POSITION_DIR = os.path.join(DATA_DIR, \"wins_above_avg_position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d55ddb-39f3-447e-8625-461b0c568483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6f24123-8c93-43c8-9c02-f4bb6a3059a7",
   "metadata": {},
   "source": [
    "There's going to be two types of URLs used in the scrapping portion of the project:\n",
    "    \n",
    "    - URL_1 is to be used to scrape the batting, fielding, pitching, and wins_above tables.\n",
    "\n",
    "    - URL_2 is to be used to scrape the schedule and season summary for each team in each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "117231d0-7ca1-4861-94ea-8c9e22832ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Season_Year = \"\"\n",
    "Team_Name = \"\"\n",
    "\n",
    "URL_1 = f\"https://www.baseball-reference.com/leagues/majors/{Season_Year}.shtml\"\n",
    "\n",
    "URL_2 = f\"https://www.baseball-reference.com/teams/{Team_Name}/{Season_Year}-schedule-scores.shtml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d81e94-2b6f-41a3-95d3-996430d52cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape html from a webpage\n",
    "\n",
    "async def get_html(url, selector, sleep=5, retries=5):\n",
    "    html = None\n",
    "    for i in range(1, retries+1):\n",
    "        time.sleep(sleep * i)\n",
    "        try:\n",
    "            print(f\"Starting scrape. Attempt {i}\")\n",
    "            async with async_playwright() as p:\n",
    "                browser = await p.firefox.launch()\n",
    "                page = await browser.new_page()\n",
    "                await page.goto(url)\n",
    "                print(await page.title())\n",
    "                html = await page.inner_html(selector)\n",
    "        except PlaywrightTimeout:\n",
    "            print(f\"Timeout error on {url}\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04c7abe1-cbbc-48f0-8c39-9aaea7bc66c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape content from each mlb season stats page\n",
    "\n",
    "async def scrape_single_season_stats(Season):\n",
    "    \n",
    "    URL_1 = f\"https://www.baseball-reference.com/leagues/majors/{Season}.shtml\"\n",
    "   \n",
    "    save_path = os.path.join(SEASON_STATS_DIR, URL_1.split(\"/\")[-1])\n",
    "\n",
    "    html = await get_html(URL_1, \"#content\")\n",
    "    with open(save_path, \"w+\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "    return \"Completed\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720c153f-d5b9-4717-82ca-58578b3792db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape content from each mlb season stats page\n",
    "\n",
    "async def scrape_season_stats(Seasons):\n",
    "\n",
    "    for season in Seasons:\n",
    "        URL_1 = f\"https://www.baseball-reference.com/leagues/majors/{season}.shtml\"\n",
    "       \n",
    "        save_path = os.path.join(SEASON_STATS_DIR, URL_1.split(\"/\")[-1])\n",
    "    \n",
    "        html = await get_html(URL_1, \"#content\")\n",
    "        with open(save_path, \"w+\") as f:\n",
    "            f.write(html)\n",
    "\n",
    "    return \"Completed\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bcb16f9-a4a3-4ecc-be97-f91ddd03581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/leagues/majors/2012.shtml\n",
      "Starting scrape. Attempt 2\n",
      "Timeout error on https://www.baseball-reference.com/leagues/majors/2012.shtml\n",
      "Starting scrape. Attempt 3\n",
      "2012 Major League Baseball Team Statistics | Baseball-Reference.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test single season scrape\n",
    "season1 = 2012\n",
    "await scrape_single_season_stats(season1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "206f84cb-5988-441a-ae9b-ed7a77c43c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a5cf40b-ab11-49ac-a74a-b5fd72ab97de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/leagues/majors/2019.shtml\n",
      "Starting scrape. Attempt 2\n",
      "Timeout error on https://www.baseball-reference.com/leagues/majors/2019.shtml\n",
      "Starting scrape. Attempt 3\n",
      "2019 Major League Baseball Team Statistics | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/leagues/majors/2020.shtml\n",
      "Starting scrape. Attempt 2\n",
      "Timeout error on https://www.baseball-reference.com/leagues/majors/2020.shtml\n",
      "Starting scrape. Attempt 3\n",
      "2020 Major League Baseball Team Statistics | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "2021 Major League Baseball Team Statistics | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/leagues/majors/2022.shtml\n",
      "Starting scrape. Attempt 2\n",
      "2022 Major League Baseball Team Statistics | Baseball-Reference.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now loop through Seasons list and scrape each seasons data\n",
    "season_list = list(range(2019,2023))\n",
    "await scrape_season_stats(season_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d029985-447f-45d9-a29e-4b5b66cdcef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scrape. Attempt 1\n",
      "2010 Major League Baseball Team Statistics | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/leagues/majors/2011.shtml\n",
      "Starting scrape. Attempt 2\n",
      "2011 Major League Baseball Team Statistics | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/leagues/majors/2012.shtml\n",
      "Starting scrape. Attempt 2\n",
      "Timeout error on https://www.baseball-reference.com/leagues/majors/2012.shtml\n",
      "Starting scrape. Attempt 3\n",
      "Timeout error on https://www.baseball-reference.com/leagues/majors/2012.shtml\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Now loop through Seasons list and scrape each seasons data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m season_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2010\u001b[39m,\u001b[38;5;241m2014\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m scrape_season_stats(season_list)\n",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m, in \u001b[0;36mscrape_season_stats\u001b[0;34m(Seasons)\u001b[0m\n\u001b[1;32m     10\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m get_html(URL_1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#content\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 12\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(html)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not None"
     ]
    }
   ],
   "source": [
    "#Now loop through Seasons list and scrape each seasons data\n",
    "season_list = list(range(2010,2014))\n",
    "await scrape_season_stats(season_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "920491fc-b659-438f-87bb-58809db2c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape content from each mlb game of season. Start with 2012 b/c miami marlines began then\n",
    "Team_LIST = ['ARI', 'ATL', 'BAL', 'BOS', 'CHC', 'CHW', 'CIN', 'CLE', 'COL', 'DET', 'HOU', 'KAN', 'LAA', 'LAD', 'MIA', 'MIL', 'MIN', 'NYM', 'NYY', 'OAK', 'PHI', 'PIT', 'SD', 'SF', 'SEA', 'STL', 'TB','TEX', 'TOR', 'WAS']\n",
    "\n",
    "\n",
    "# ['ARI', 'ATL', 'BAL', 'BOS', 'CHC', 'CHW', 'CIN', 'CLE', 'COL', 'DET', 'HOU', 'KAN', 'LAA', 'LAD', 'MIA', 'MIL', 'MIN', 'NYM', 'NYY', 'OAK', 'PHI', 'PIT', 'SD', 'SF', 'SEA', 'STL', 'TB',\n",
    "#Season = 2012\n",
    "\n",
    "\n",
    "async def scrape_games(Team_list, Season):\n",
    "    for team in Team_list:\n",
    "        URL_2 = f\"https://www.baseball-reference.com/teams/{team}/{Season}-schedule-scores.shtml\"\n",
    "       \n",
    "        save_path = os.path.join(GAMES_DIR, URL_2.split(\"/\")[-2])\n",
    "    \n",
    "        html = await get_html(URL_2, \"#content\")\n",
    "        if (html):\n",
    "            with open(save_path, \"w+\") as f:\n",
    "                f.write(html)\n",
    "\n",
    "    return \"Completed\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d730e833-d5b6-41bf-9bc0-5f146dae9e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/teams/ARI/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 2\n",
      "2014 Arizona Diamondbacks Schedule | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "2014 Atlanta Braves Schedule | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "2014 Baltimore Orioles Schedule | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/teams/BOS/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 2\n",
      "Timeout error on https://www.baseball-reference.com/teams/BOS/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 3\n",
      "Timeout error on https://www.baseball-reference.com/teams/BOS/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 4\n",
      "Timeout error on https://www.baseball-reference.com/teams/BOS/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 5\n",
      "2014 Boston Red Sox Schedule | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/teams/CHC/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 2\n",
      "Timeout error on https://www.baseball-reference.com/teams/CHC/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 3\n",
      "Timeout error on https://www.baseball-reference.com/teams/CHC/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 4\n",
      "Timeout error on https://www.baseball-reference.com/teams/CHC/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 5\n",
      "Timeout error on https://www.baseball-reference.com/teams/CHC/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 1\n",
      "2014 Chicago White Sox Schedule | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/teams/CIN/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 2\n",
      "Timeout error on https://www.baseball-reference.com/teams/CIN/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 3\n",
      "Timeout error on https://www.baseball-reference.com/teams/CIN/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 4\n",
      "Timeout error on https://www.baseball-reference.com/teams/CIN/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 5\n",
      "2014 Cincinnati Reds Schedule | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "2014 Cleveland Indians Schedule | Baseball-Reference.com\n",
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/teams/COL/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 2\n",
      "Timeout error on https://www.baseball-reference.com/teams/COL/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 3\n",
      "Timeout error on https://www.baseball-reference.com/teams/COL/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 4\n",
      "Timeout error on https://www.baseball-reference.com/teams/COL/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 5\n",
      "Timeout error on https://www.baseball-reference.com/teams/COL/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/teams/DET/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 2\n",
      "Timeout error on https://www.baseball-reference.com/teams/DET/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 3\n",
      "Timeout error on https://www.baseball-reference.com/teams/DET/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 4\n",
      "Timeout error on https://www.baseball-reference.com/teams/DET/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 5\n",
      "Timeout error on https://www.baseball-reference.com/teams/DET/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 1\n",
      "Timeout error on https://www.baseball-reference.com/teams/HOU/2014-schedule-scores.shtml\n",
      "Starting scrape. Attempt 2\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Due to complexity, manually scrape each season from 2012 - 2022\u001b[39;00m\n\u001b[1;32m      2\u001b[0m Season \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2014\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m scrape_games(Team_LIST, Season)\n",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m, in \u001b[0;36mscrape_games\u001b[0;34m(Team_list, Season)\u001b[0m\n\u001b[1;32m     11\u001b[0m URL_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.baseball-reference.com/teams/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSeason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-schedule-scores.shtml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(GAMES_DIR, URL_2\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m get_html(URL_2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#content\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (html):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m, in \u001b[0;36mget_html\u001b[0;34m(url, selector, sleep, retries)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting scrape. Attempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m async_playwright() \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m     10\u001b[0m         browser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m p\u001b[38;5;241m.\u001b[39mfirefox\u001b[38;5;241m.\u001b[39mlaunch()\n\u001b[1;32m     11\u001b[0m         page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m browser\u001b[38;5;241m.\u001b[39mnew_page()\n",
      "File \u001b[0;32m~/anaconda3/envs/XAPE/lib/python3.11/site-packages/playwright/async_api/_context_manager.py:40\u001b[0m, in \u001b[0;36mPlaywrightContextManager.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m loop\u001b[38;5;241m.\u001b[39mcreate_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mrun())\n\u001b[1;32m     38\u001b[0m playwright_future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mplaywright_future\n\u001b[0;32m---> 40\u001b[0m done, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m     41\u001b[0m     {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mon_error_future, playwright_future},\n\u001b[1;32m     42\u001b[0m     return_when\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39mFIRST_COMPLETED,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m playwright_future\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     45\u001b[0m     playwright_future\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/anaconda3/envs/XAPE/lib/python3.11/asyncio/tasks.py:418\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing coroutines is forbidden, use tasks explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    417\u001b[0m loop \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mget_running_loop()\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _wait(fs, timeout, return_when, loop)\n",
      "File \u001b[0;32m~/anaconda3/envs/XAPE/lib/python3.11/asyncio/tasks.py:525\u001b[0m, in \u001b[0;36m_wait\u001b[0;34m(fs, timeout, return_when, loop)\u001b[0m\n\u001b[1;32m    522\u001b[0m     f\u001b[38;5;241m.\u001b[39madd_done_callback(_on_completion)\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Due to complexity, manually scrape each season from 2012 - 2022\n",
    "Season = 2014\n",
    "await scrape_games(Team_LIST, Season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc99923-3d39-41fd-a220-433dc09a42b4",
   "metadata": {},
   "source": [
    "One of the big issues I ran into was simple error with the playwright execution. It would work for most of the files, but after my initial build of the data set, I know that I will be missing\n",
    "1 - 2 files per season and will need to go back and grab those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34069170-0010-4434-83c8-aeab68f4260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test single season scrape\n",
    "#await scrape_games(Team_LIST, Season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727d268-12f2-4377-945a-508ae3a295b1",
   "metadata": {},
   "source": [
    "So now I have a full season of data for the 2012 season. I have this data in a series of html files, so the next step will be to preprocess these files.\n",
    "I want to go through the html and pull out the relavant data tables, and then put that data in an organized file system. I can then use python and SQL to \n",
    "configure training and testing datasets. \n",
    "\n",
    "Once the script to process and organize the data is complete, I will write a systematic process for gather data from X to Y years, processing that data, and saving everything in valuable way for training & testing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d2707-31a5-4766-aa87-68eeed6bfe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
